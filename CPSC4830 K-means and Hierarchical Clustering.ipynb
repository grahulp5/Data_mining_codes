{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0a16603",
   "metadata": {},
   "source": [
    "K-means\n",
    "Artificially generate a dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb9eead",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "\n",
    "# Generate a synthetic dataset\n",
    "X, _ = make_blobs(n_samples=1000, centers=4, cluster_std=0.5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e3ee77",
   "metadata": {},
   "source": [
    "Modeling (note: we don't have split dataset. It can be called training, provided that you have new data comes in. If you have a fixed dataset, some of the time we call it modeling.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95cc1b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Re-importing necessary libraries after reset\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Apply KMeans clustering\n",
    "kmeans = KMeans(n_clusters=4)\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "234d459c",
   "metadata": {},
   "source": [
    "Plot graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7ea1da3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting the clusters\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y_kmeans, s=50, cmap='viridis')\n",
    "\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5)  # Mark the centroids\n",
    "plt.title(\"K-Means Clustering\")\n",
    "plt.xlabel(\"Feature 1\")\n",
    "plt.ylabel(\"Feature 2\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1aa4313",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "Change the number of clusters by n_clusters, by default n_clusters=8\n",
    "Change the initialization method by init, by default init='k-means++'\n",
    "Set the maximum iterations by max_iter, by default max_iter=300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e4b0271",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply KMeans clustering\n",
    "#kmeans = KMeans(n_clusters=4)\n",
    "kmeans = KMeans(n_clusters=10, init='random', max_iter=1000)\n",
    "\n",
    "kmeans.fit(X)\n",
    "y_kmeans = kmeans.predict(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be24e220",
   "metadata": {},
   "source": [
    "Let's try Iris data again.\n",
    "If we remove Iris data label, then we can apply K-means and construct the confusion matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a12fe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Load the Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n",
    "\n",
    "# Apply KMeans clustering\n",
    "# Since we know there are 3 species of iris in the dataset, we'll use n_clusters=3\n",
    "kmeans = KMeans(n_clusters=3, random_state=42)\n",
    "kmeans.fit(X)\n",
    "\n",
    "# Predict the cluster labels\n",
    "labels = kmeans.predict(X)\n",
    "\n",
    "# Visualizing the clusters - we'll use the first two features for simplicity\n",
    "plt.scatter(X[:, 0], X[:, 1], c=labels, cmap='viridis', edgecolor='k', s=50)\n",
    "centers = kmeans.cluster_centers_\n",
    "plt.scatter(centers[:, 0], centers[:, 1], c='red', s=200, alpha=0.5, marker='X')  # Mark the centroids\n",
    "plt.title('K-Means Clustering on Iris Dataset')\n",
    "plt.xlabel(iris.feature_names[0])\n",
    "plt.ylabel(iris.feature_names[1])\n",
    "plt.show()\n",
    "\n",
    "# Since we have the true labels, we can compare them to our k-means labels\n",
    "# Note: This is just for educational purposes; in real-world unsupervised learning scenarios, we usually don't have true labels.\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score\n",
    "\n",
    "# A simple function to relabel the clusters to match the original labels as closely as possible for accuracy calculation\n",
    "def relabel_clusters(labels, true_labels):\n",
    "    from scipy.stats import mode\n",
    "    new_labels = np.zeros_like(labels)\n",
    "    for i in range(3):\n",
    "        mask = (labels == i)\n",
    "        new_labels[mask] = mode(true_labels[mask])[0]\n",
    "    return new_labels\n",
    "\n",
    "new_labels = relabel_clusters(labels, y)\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y, new_labels))\n",
    "print(f\"Accuracy: {accuracy_score(y, new_labels):.2f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9faa359",
   "metadata": {},
   "source": [
    "Hierarchical Clustering\n",
    "Create a sample data first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9292ad0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_blobs\n",
    "from sklearn.cluster import AgglomerativeClustering\n",
    "from scipy.cluster.hierarchy import dendrogram, linkage\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generating a synthetic dataset\n",
    "X, labels_true = make_blobs(n_samples=150, centers=3, cluster_std=0.60, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "674bd4f1",
   "metadata": {},
   "source": [
    "Develop the Dendrogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3609ed59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the linkage matrix\n",
    "Z = linkage(X, 'ward')\n",
    "\n",
    "# Plotting the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c197691f",
   "metadata": {},
   "source": [
    "Linkage methods:\n",
    "'single': Uses the minimum of the distances between all observations of the two sets.\n",
    "'complete': Uses the maximum distances between all observations of the two sets.\n",
    "'average': Uses the average of the distances of each observation of the two sets.\n",
    "'ward': Minimizes the variance of the clusters being merged."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dbffca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating the linkage matrix\n",
    "Z = linkage(X, 'complete')\n",
    "\n",
    "# Plotting the dendrogram\n",
    "plt.figure(figsize=(10, 7))\n",
    "plt.title(\"Hierarchical Clustering Dendrogram\")\n",
    "plt.xlabel(\"Sample index\")\n",
    "plt.ylabel(\"Distance\")\n",
    "dendrogram(\n",
    "    Z,\n",
    "    leaf_rotation=90.,  # rotates the x axis labels\n",
    "    leaf_font_size=8.,  # font size for the x axis labels\n",
    ")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c28a578",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
