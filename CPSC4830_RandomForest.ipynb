{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5d53799a",
   "metadata": {},
   "source": [
    "Import packages and data\n",
    "Use Iris data as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7da5048b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Load Iris dataset\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92bc590",
   "metadata": {},
   "source": [
    "Split data into training and testing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a5e808",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data - 80% training, 20% test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89cd0695",
   "metadata": {},
   "source": [
    "Initialize the Random Forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd1d7f1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Random Forest Classifier\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af99ca4e",
   "metadata": {},
   "source": [
    "Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5a46463",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "rf_clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c72d78dd",
   "metadata": {},
   "source": [
    "Predict (Testing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a6d01a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict on the test set\n",
    "y_pred = rf_clf.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64fd6692",
   "metadata": {},
   "source": [
    "Validation (Evaulation) of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da490060",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1686f8",
   "metadata": {},
   "source": [
    "Now, let's check what you can play with the Random Forest.\n",
    "\n",
    "What is covered in the lecture?\n",
    "\n",
    "1. Number of trees in the forest\n",
    "2. Depth of each tree\n",
    "3. How many samples in each tree\n",
    "4. How many features in each tree\n",
    "5. Node splitting method and number of samples in a node\n",
    "\n",
    "There are some more parameters that you can change. You can explore by yourself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6021a817",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set 200 individual trees\n",
    "#rf_clf = RandomForestClassifier(n_estimators=200, random_state=42)\n",
    "\n",
    "# Set the maximum depth of each tree to 3\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, max_depth=3, random_state=42)\n",
    "\n",
    "# Set criterion, default = gini, and you can choose information gain\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, criterion=\"entropy\", random_state=42)\n",
    "\n",
    "# Set minimum samples to split in a node, default = 2\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, min_samples_split=5, random_state=42)\n",
    "\n",
    "# Set min_samples_leaf is similar to minimum samples to split at node, to avoid overfitting, default = 1\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, min_samples_leaf=5, random_state=42)\n",
    "\n",
    "# Set max_leaf_nodes is similar, to avoid overfitting, default no limit\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, max_leaf_nodes=5, random_state=42)\n",
    "\n",
    "# Set max features in a tree, default = sqrt(total features)\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, max_features='log2', random_state=42)\n",
    "\n",
    "# Set max samples in a tree, default same as the original data set size\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, max_samples=100, random_state=42)\n",
    "\n",
    "# Warm start means you are NOT starting from nothing, but USING the PREVIOUS result to train!\n",
    "# That means you add more trees to do the training (same as increasing the n_estimators at first)\n",
    "#rf_clf = RandomForestClassifier(n_estimators=100, warm_start='True', random_state=42)\n",
    "\n",
    "# n_jobs means ask how many computer cores to run the job. n_jobs = '-1' means use all cores. default = 'None'\n",
    "rf_clf = RandomForestClassifier(n_estimators=100, n_jobs = -1, random_state=42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80a015ed",
   "metadata": {},
   "source": [
    "Draw the trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01a39ab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import plot_tree\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Select a tree from the random forest\n",
    "tree = rf_clf.estimators_[0]  # Selecting the first tree as an example\n",
    "\n",
    "# Plot the decision tree\n",
    "plt.figure(figsize=(20, 10))\n",
    "plot_tree(tree, feature_names=iris.feature_names, class_names=iris.target_names.tolist(), filled=True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fee51317",
   "metadata": {},
   "source": [
    "Which features are important?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e67de8",
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = rf_clf.feature_importances_\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Get feature names\n",
    "feature_names = iris.feature_names\n",
    "\n",
    "# Sort the feature importances in descending order\n",
    "sorted_idx = np.argsort(feature_importances)[::-1]\n",
    "\n",
    "# Plot the feature importances\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.bar(range(X.shape[1]), feature_importances[sorted_idx], align='center')\n",
    "plt.xticks(range(X.shape[1]), np.array(feature_names)[sorted_idx], rotation=45)\n",
    "plt.title('Feature Importance in Random Forest')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "148b2e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
