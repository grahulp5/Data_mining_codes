{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7e0282ba",
   "metadata": {},
   "source": [
    "Let's try a toy model first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03018dbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afd6696b",
   "metadata": {},
   "source": [
    "Estimate the coefficient Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd7c1dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimate_coef(x, y):\n",
    "  # number of observations/points\n",
    "  n = np.size(x)\n",
    " \n",
    "  # mean of x and y vector\n",
    "  m_x = np.mean(x)\n",
    "  m_y = np.mean(y)\n",
    " \n",
    "  # calculating cross-deviation and deviation about x\n",
    "  SS_xy = np.sum(y*x) - n*m_y*m_x\n",
    "  SS_xx = np.sum(x*x) - n*m_x*m_x\n",
    " \n",
    "  # calculating regression coefficients\n",
    "  b_1 = SS_xy / SS_xx\n",
    "  b_0 = m_y - b_1*m_x\n",
    "    \n",
    "  return (b_0, b_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d3759",
   "metadata": {},
   "source": [
    "Plot Regression Function\n",
    "We have true value of y.\n",
    "Here we create a scatter plot for x and y, and fit the line and draw the line on th"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a27ebfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_regression_line(x, y, b):\n",
    "  # plotting the actual points as scatter plot\n",
    "  plt.scatter(x, y, color = \"m\",\n",
    "        marker = \"o\", s = 30)\n",
    " \n",
    "  # predicted response vector\n",
    "  y_pred = b[0] + b[1]*x\n",
    " \n",
    "  # plotting the regression line\n",
    "  plt.plot(x, y_pred, color = \"g\")\n",
    " \n",
    "  # putting labels\n",
    "  plt.xlabel('x')\n",
    "  plt.ylabel('y')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cf622f7",
   "metadata": {},
   "source": [
    "Let's try it out now."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d215339a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# observations / data\n",
    "x = np.array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
    "y = np.array([1, 3, 2, 5, 7, 8, 8, 9, 10, 12])\n",
    " \n",
    "# estimating coefficients\n",
    "b = estimate_coef(x, y)\n",
    "print(\"Estimated coefficients:\\nb_0 = {} \\nb_1 = {}\".format(*b))\n",
    "\n",
    "plot_regression_line(x, y, b)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80425a12",
   "metadata": {},
   "source": [
    "Calculate R Square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3a36b91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = b[0] + b[1]*x\n",
    "\n",
    "# calculating the mean of y\n",
    "m_y = np.mean(y)\n",
    "\n",
    "# calculating total sum of squares\n",
    "SST = np.sum((y - m_y)*(y - m_y))\n",
    "\n",
    "# calculating residual sum of squares\n",
    "SSRes = np.sum((y - y_pred)*(y - y_pred))\n",
    "\n",
    "# calculating R-squared\n",
    "R_squared = 1 - (SSRes/SST)\n",
    "\n",
    "print(\"R-Squared = \", R_squared)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f407e253",
   "metadata": {},
   "source": [
    "After playing with this toy model, let's try real case.\n",
    "\n",
    "Multiple Linear Regression\n",
    "i.e. A lot more Xi for input\n",
    "\n",
    "Import Libraries\n",
    "There are a lot packages provide linear regression model: sklearn, statsmodels, scipy, etc.\n",
    "The procedure is similar, but with different target. We will come back to this point later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64c9f90f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets, linear_model, metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267ca09d",
   "metadata": {},
   "source": [
    "Input file\n",
    "The given one is an example.\n",
    "Here you can have more sample data to play with:\n",
    "https://people.sc.fsu.edu/~jburkardt/datasets/regression/regression.html\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae88a1ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_url = \"http://lib.stat.cmu.edu/datasets/boston\"\n",
    "raw_df = pd.read_csv(data_url, sep=\"\\s+\", skiprows=22, header=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3609ee92",
   "metadata": {},
   "source": [
    "Data Pre-processing\n",
    "We extract the input variables (X) and target variable (y) from the DataFrame. The input variables are selected from every other row to match the target variable, which is available every other row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4fd96f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.hstack([raw_df.values[::2, :], raw_df.values[1::2, :2]])\n",
    "y = raw_df.values[1::2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5eb5ecd",
   "metadata": {},
   "source": [
    "Splitting Data into Training and Testing Sets\n",
    "\n",
    "Rule of thumb for large dataset:\n",
    "40% for training, 30% for validation, 30% for testing\n",
    "\n",
    "Rule of thumb for small but still moderate dataset:\n",
    "70% for training and 30% for testing (Skip validation)\n",
    "\n",
    "Rule of thumb for very small dataset:\n",
    "Cross-Validation, 5-fold or X-fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "787394f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "310fae28",
   "metadata": {},
   "source": [
    "Training Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db79b72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = linear_model.LinearRegression()\n",
    "reg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca3ae2a",
   "metadata": {},
   "source": [
    "Evaluating Model Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7a6a0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regression coefficients\n",
    "print('Coefficients: ', reg.coef_)\n",
    " \n",
    "# variance score: 1 means perfect prediction\n",
    "print('R-Squared: {}'.format(reg.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6d993c2",
   "metadata": {},
   "source": [
    "Plotting Residual Errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eaa478",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot for residual error\n",
    " \n",
    "# setting plot style\n",
    "plt.style.use('fivethirtyeight')\n",
    " \n",
    "# plotting residual errors in training data\n",
    "plt.scatter(reg.predict(X_train),\n",
    "            reg.predict(X_train) - y_train,\n",
    "            color=\"green\", s=10,\n",
    "            label='Train data')\n",
    " \n",
    "# plotting residual errors in test data\n",
    "plt.scatter(reg.predict(X_test),\n",
    "            reg.predict(X_test) - y_test,\n",
    "            color=\"blue\", s=10,\n",
    "            label='Test data')\n",
    " \n",
    "# plotting line for zero residual error\n",
    "plt.hlines(y=0, xmin=0, xmax=50, linewidth=2)\n",
    " \n",
    "# plotting legend\n",
    "plt.legend(loc='upper right')\n",
    " \n",
    "# plot title\n",
    "plt.title(\"Residual errors\")\n",
    " \n",
    "# method call for showing the plot\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56e7ac63",
   "metadata": {},
   "source": [
    "P-value for each coefficient?\n",
    "Feature selection?\n",
    "\n",
    "In scikit-learn's LinearRegression model, there isn't a direct method to calculate the p-values for the regression coefficients. Scikit-learn focuses more on prediction than on statistical inference, which is why some statistical metrics like p-values are not readily available.\n",
    "\n",
    "So, we can calculate the p-values using statsmodels, which is more oriented towards statistical analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341dedff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "import numpy as np\n",
    "\n",
    "X_train = sm.add_constant(X_train)\n",
    "\n",
    "# Fit the model\n",
    "model = sm.OLS(y_train, X_train).fit()\n",
    "\n",
    "# Print the summary\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70d1e1c9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
